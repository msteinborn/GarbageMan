"""
RAG Service for Business Terms
Standalone service for retrieval augmented generation
"""

import os
import csv
from pathlib import Path
from typing import List, Dict
from sentence_transformers import SentenceTransformer
import chromadb
from scraper import InvestopediaScraper

# Initialize embedding model
EMBEDDING_MODEL = SentenceTransformer('all-MiniLM-L6-v2')

# Initialize Chroma (local vector database) - using new API
CHROMA_DIR = "./chroma_data"
if not os.path.exists(CHROMA_DIR):
    os.makedirs(CHROMA_DIR)

client = chromadb.PersistentClient(path=CHROMA_DIR)


def load_from_csv(csv_path: str) -> List[Dict]:
    """
    Load business terms from a local CSV file
    
    Args:
        csv_path: Path to CSV with 'term' and 'definition' columns
        
    Returns:
        List of term dictionaries
    """
    terms = []
    try:
        with open(csv_path, 'r', encoding='utf-8') as f:
            reader = csv.DictReader(f)
            for row in reader:
                if row.get('term') and row.get('definition'):
                    terms.append({
                        "term": row['term'].strip(),
                        "definition": row['definition'].strip()
                    })
        print(f"âœ“ Loaded {len(terms)} terms from {csv_path}")
        return terms
    except FileNotFoundError:
        print(f"âš ï¸  CSV not found at {csv_path}")
        return []
    except Exception as e:
        print(f"âš ï¸  Error loading CSV: {e}")
        return []


def fetch_business_terms_dataset() -> List[Dict]:
    """
    Fetch business terms dataset with fallback chain:
    1. Try loading from local CSV
    2. Try scraping Investopedia
    3. Use fallback dataset
    """
    print("ğŸ“¥ Fetching business terms dataset...")
    
    # Check for local CSV first
    csv_path = "business_terms.csv"
    if os.path.exists(csv_path):
        print(f"ğŸ“„ Found local CSV at {csv_path}")
        terms = load_from_csv(csv_path)
        if terms:
            return terms
    
    # Try scraping Investopedia
    print("ğŸŒ Attempting to scrape Investopedia...")
    try:
        scraper = InvestopediaScraper(csv_path)
        terms = scraper.scrape_all()
        if terms:
            scraper.save_to_csv()
            return terms
    except Exception as e:
        print(f"âš ï¸  Scraping failed: {e}")
    
    # Fallback to hardcoded dataset
    print("ğŸ“¥ Using fallback dataset...")
    return get_fallback_business_terms()


def get_fallback_business_terms() -> List[Dict]:
    """Fallback dataset if online fetch fails"""
    return [
        {"term": "ROI", "definition": "Return on Investment - a measure of profit relative to investment"},
        {"term": "KPI", "definition": "Key Performance Indicator - measurable value showing effectiveness"},
        {"term": "EBITDA", "definition": "Earnings Before Interest, Taxes, Depreciation, and Amortization"},
        {"term": "Cash Flow", "definition": "Movement of money in and out of a business"},
        {"term": "Market Cap", "definition": "Total market value of a company's shares"},
        {"term": "Revenue", "definition": "Total income generated by sales of goods/services"},
        {"term": "P&L", "definition": "Profit and Loss statement showing financial performance"},
        {"term": "Amortization", "definition": "Spreading cost of intangible asset over useful life"},
        {"term": "Burn Rate", "definition": "Rate at which company spends cash reserves"},
        {"term": "Runway", "definition": "Time a company can operate with current cash"},
        {"term": "IPO", "definition": "Initial Public Offering - first time company sells shares publicly"},
        {"term": "Equity", "definition": "Ownership stake in a company"},
        {"term": "Debt", "definition": "Money borrowed that must be repaid with interest"},
        {"term": "Asset", "definition": "Anything of value owned by a business"},
        {"term": "Liability", "definition": "Financial obligation or debt owed by business"},
    ]


def create_vector_store(terms: List[Dict]):
    """
    Create vector embeddings and store in Chroma
    Handles large batches by splitting into smaller chunks
    """
    print("ğŸ”„ Creating vector embeddings...")
    
    # Create collection
    collection = client.get_or_create_collection(
        name="business_terms",
        metadata={"hnsw:space": "cosine"}
    )
    
    # Prepare data
    ids = []
    documents = []
    metadatas = []
    embeddings = []
    
    for idx, item in enumerate(terms):
        term = item["term"]
        definition = item["definition"]
        
        # Create document: term + definition for better context
        doc = f"Term: {term}\nDefinition: {definition}"
        
        # Generate embedding
        embedding = EMBEDDING_MODEL.encode(doc).tolist()
        
        ids.append(f"term_{idx}")
        documents.append(doc)
        embeddings.append(embedding)
        metadatas.append({
            "term": term,
            "definition": definition
        })
    
    # Add to collection in batches (Chroma max batch size is 5461)
    batch_size = 5000
    total_added = 0
    
    for batch_start in range(0, len(ids), batch_size):
        batch_end = min(batch_start + batch_size, len(ids))
        
        batch_ids = ids[batch_start:batch_end]
        batch_documents = documents[batch_start:batch_end]
        batch_embeddings = embeddings[batch_start:batch_end]
        batch_metadatas = metadatas[batch_start:batch_end]
        
        collection.add(
            ids=batch_ids,
            embeddings=batch_embeddings,
            documents=batch_documents,
            metadatas=batch_metadatas
        )
        
        total_added += len(batch_ids)
        print(f"  âœ“ Added batch: {batch_start}-{batch_end}")
    
    print(f"âœ“ Stored {total_added} terms in vector database")
    return collection


def retrieve_relevant_terms(query: str, collection, top_k: int = 3) -> List[Dict]:
    """
    Retrieve relevant business terms for a query
    """
    # Embed the query
    query_embedding = EMBEDDING_MODEL.encode(query).tolist()
    
    # Search in collection
    results = collection.query(
        query_embeddings=[query_embedding],
        n_results=top_k
    )
    
    # Format results
    retrieved = []
    if results['metadatas'] and results['metadatas'][0]:
        for i, metadata in enumerate(results['metadatas'][0]):
            retrieved.append({
                "term": metadata["term"],
                "definition": metadata["definition"],
                "distance": results['distances'][0][i] if 'distances' in results else 0
            })
    
    return retrieved


def generate_rag_response(query: str, retrieved_terms: List[Dict]) -> str:
    """
    Generate response using RAG (Retrieved context + LLM)
    For now, formats retrieved context as structured response
    """
    response = f"Query: {query}\n\n"
    response += "ğŸ“š Retrieved Business Terms:\n"
    response += "=" * 50 + "\n"
    
    if retrieved_terms:
        for item in retrieved_terms:
            response += f"\nğŸ“Œ {item['term']}\n"
            response += f"   {item['definition']}\n"
    else:
        response += "No matching terms found.\n"
    
    return response


def main():
    """Main RAG pipeline"""
    print("\nğŸš€ Business Terms RAG Service\n")
    
    # Step 1: Fetch dataset
    terms = fetch_business_terms_dataset()
    
    # Step 2: Create vector store
    collection = create_vector_store(terms)
    
    # Step 3: Interactive retrieval
    print("\nğŸ’¬ Enter queries (type 'exit' to quit):\n")
    
    while True:
        query = input("Query: ").strip()
        
        if query.lower() == 'exit':
            print("Goodbye! ğŸ‘‹")
            break
        
        if not query:
            continue
        
        # Retrieve relevant terms
        retrieved = retrieve_relevant_terms(query, collection, top_k=3)
        
        # Generate response
        response = generate_rag_response(query, retrieved)
        print(response)
        print("-" * 50 + "\n")


if __name__ == "__main__":
    main()
